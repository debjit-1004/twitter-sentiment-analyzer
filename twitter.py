# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LrT2pQ9jk9-360Sl_F6JyoULzed0VQkT
"""

from transformers import AutoTokenizer,AutoModelForSequenceClassification
from scipy.special import softmax

tweet = "@debjit today's  weather is nice and sunny in #kolkata #weather #sunnyday ðŸ˜Š https://www.google.com"

# prepocess tweet
tweet_words=[]

for word in  tweet.split(' '):
    if word.startswith('@') and len(word)>1:
        word= '@user'

    elif word.startswith('http'):
        word='http'

    tweet_words.append(word)

tweet_proc=" ".join(tweet_words)
print(tweet_proc)

#load the model and tokenizer
roberta = "cardiffnlp/twitter-roberta-base-sentiment-latest"

model= AutoModelForSequenceClassification.from_pretrained(roberta)

tokeneizer = AutoTokenizer.from_pretrained(roberta)

labels= ['Negative', 'Neutral','Positive']

#sentiment analysis

encoded_tweet=tokeneizer(tweet_proc, return_tensors='pt')

print(encoded_tweet)

output=model(encoded_tweet['input_ids'],encoded_tweet['attention_mask'])
print(output)

#get the probabilty

scores =output[0][0].detach().numpy()
scores= softmax(scores)
print(scores)

for i in range(len(scores)):
  l=labels[i]
  s=scores[i]
  print(l,s)